{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text proccessing kelompok kapsel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkSHpb2Fjyec",
        "outputId": "ec81895f-6ac9-428b-fbe6-94be3c27dfcf"
      },
      "source": [
        "!git clone https://github.com/renatasuyudi/kapsel.git"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'kapsel' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDS4budnatLg"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez_sUz4UmCTY"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnXp6a28nNL2"
      },
      "source": [
        "data1 = pd.read_json('/content/kapsel/data/dataPCR.json', lines=True)\n",
        "data2 = pd.read_json('/content/kapsel/data/datacovid.json', lines=True)\n",
        "data3 = pd.read_json('/content/kapsel/data/datacovid19.json', lines=True)\n",
        "data4 = pd.read_json('/content/kapsel/data/dataisoman.json', lines=True)\n",
        "data5 = pd.read_json('/content/kapsel/data/datakarantina.json', lines=True)\n",
        "data6 = pd.read_json('/content/kapsel/data/datapandemicovid.json', lines=True)\n",
        "data7 = pd.read_json('/content/kapsel/data/datappkm.json', lines=True)\n",
        "data8 = pd.read_json('/content/kapsel/data/datapsbb.json', lines=True)\n",
        "data9 = pd.read_json('/content/kapsel/data/dataswab.json', lines=True)\n",
        "data=pd.concat([data1,data2,data3,data4,data5,data6,data7,data8,data9]).reset_index(drop=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "5ngaTPjfo5Rx",
        "outputId": "97f474ca-b3a8-43bc-c1b1-3744a3ad2ff6"
      },
      "source": [
        "data"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>id_str</th>\n",
              "      <th>full_text</th>\n",
              "      <th>truncated</th>\n",
              "      <th>display_text_range</th>\n",
              "      <th>entities</th>\n",
              "      <th>metadata</th>\n",
              "      <th>source</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_status_id_str</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>in_reply_to_user_id_str</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>user</th>\n",
              "      <th>geo</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>place</th>\n",
              "      <th>contributors</th>\n",
              "      <th>retweeted_status</th>\n",
              "      <th>is_quote_status</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>favorited</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>lang</th>\n",
              "      <th>quoted_status_id</th>\n",
              "      <th>quoted_status_id_str</th>\n",
              "      <th>quoted_status</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>extended_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-10-30 14:04:48+00:00</td>\n",
              "      <td>1454449208606429184</td>\n",
              "      <td>1454449208606429184</td>\n",
              "      <td>RT @perupadata: Resmi: harga tes RT-PCR turun....</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 139]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 105504840, 'id_str': '105504840', 'name...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Wed Oct 27 10:28:23 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-10-30 14:04:27+00:00</td>\n",
              "      <td>1454449121989824519</td>\n",
              "      <td>1454449121989824512</td>\n",
              "      <td>RT @detikfinance: #mostpop Mantan Sekretaris M...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 139]</td>\n",
              "      <td>{'hashtags': [{'text': 'mostpop', 'indices': [...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1019403817295605760, 'id_str': '1019403...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Sat Oct 30 13:48:14 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-10-30 14:04:26+00:00</td>\n",
              "      <td>1454449116356907016</td>\n",
              "      <td>1454449116356907008</td>\n",
              "      <td>@mindweul Biar bersatu dgn pcr gepengmu</td>\n",
              "      <td>False</td>\n",
              "      <td>[10, 39]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>1.454449e+18</td>\n",
              "      <td>1.454449e+18</td>\n",
              "      <td>1.451753e+18</td>\n",
              "      <td>1.451753e+18</td>\n",
              "      <td>mindweul</td>\n",
              "      <td>{'id': 1160690231865008128, 'id_str': '1160690...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-10-30 14:04:25+00:00</td>\n",
              "      <td>1454449111919325189</td>\n",
              "      <td>1454449111919325184</td>\n",
              "      <td>RT @ManassaDaeng: Pemerimtah sudah menurunkan ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 140]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1192569236494749696, 'id_str': '1192569...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Sat Oct 30 01:33:28 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-10-30 14:04:12+00:00</td>\n",
              "      <td>1454449059004092417</td>\n",
              "      <td>1454449059004092416</td>\n",
              "      <td>@2pec__ agr pcr</td>\n",
              "      <td>False</td>\n",
              "      <td>[8, 15]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>1.454449e+18</td>\n",
              "      <td>1.454449e+18</td>\n",
              "      <td>7.982780e+17</td>\n",
              "      <td>7.982780e+17</td>\n",
              "      <td>2pec__</td>\n",
              "      <td>{'id': 1107842529590951936, 'id_str': '1107842...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30098</th>\n",
              "      <td>2021-10-27 03:38:19+00:00</td>\n",
              "      <td>1453204387006857223</td>\n",
              "      <td>1453204387006857216</td>\n",
              "      <td>Antisipasi Gelombang III Covid-19, BNN Prov Su...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 273]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 2923492080, 'id_str': '2923492080', 'na...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'media': [{'id': 1453203835674005507, 'id_str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30099</th>\n",
              "      <td>2021-10-27 03:38:18+00:00</td>\n",
              "      <td>1453204381885554691</td>\n",
              "      <td>1453204381885554688</td>\n",
              "      <td>@Hilmi28 dan saya ngalamin ðŸ˜‘\\nswab antigen 170...</td>\n",
              "      <td>False</td>\n",
              "      <td>[9, 151]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>1.452798e+18</td>\n",
              "      <td>1.452798e+18</td>\n",
              "      <td>6.506718e+07</td>\n",
              "      <td>6.506718e+07</td>\n",
              "      <td>Hilmi28</td>\n",
              "      <td>{'id': 1120730554645630976, 'id_str': '1120730...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30100</th>\n",
              "      <td>2021-10-27 03:36:42+00:00</td>\n",
              "      <td>1453203977349177348</td>\n",
              "      <td>1453203977349177344</td>\n",
              "      <td>mana tadi idung aing di rojok dalem pisan, ya ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 62]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1417918233349292032, 'id_str': '1417918...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30101</th>\n",
              "      <td>2021-10-27 03:36:31+00:00</td>\n",
              "      <td>1453203931870347264</td>\n",
              "      <td>1453203931870347264</td>\n",
              "      <td>ples td di sekolah tbtb swab dadakan</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 36]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1376937657939333126, 'id_str': '1376937...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30102</th>\n",
              "      <td>2021-10-27 03:34:31+00:00</td>\n",
              "      <td>1453203430420271106</td>\n",
              "      <td>1453203430420271104</td>\n",
              "      <td>KOMPAK, TIGA PILAR BERSAMA PUSKESMAS JETIS TUR...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 255]</td>\n",
              "      <td>{'hashtags': [{'text': 'OpsYustisi', 'indices'...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1323130916206645248, 'id_str': '1323130...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'media': [{'id': 1453203020896878603, 'id_str...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30103 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     created_at  ...                                  extended_entities\n",
              "0     2021-10-30 14:04:48+00:00  ...                                                NaN\n",
              "1     2021-10-30 14:04:27+00:00  ...                                                NaN\n",
              "2     2021-10-30 14:04:26+00:00  ...                                                NaN\n",
              "3     2021-10-30 14:04:25+00:00  ...                                                NaN\n",
              "4     2021-10-30 14:04:12+00:00  ...                                                NaN\n",
              "...                         ...  ...                                                ...\n",
              "30098 2021-10-27 03:38:19+00:00  ...  {'media': [{'id': 1453203835674005507, 'id_str...\n",
              "30099 2021-10-27 03:38:18+00:00  ...                                                NaN\n",
              "30100 2021-10-27 03:36:42+00:00  ...                                                NaN\n",
              "30101 2021-10-27 03:36:31+00:00  ...                                                NaN\n",
              "30102 2021-10-27 03:34:31+00:00  ...  {'media': [{'id': 1453203020896878603, 'id_str...\n",
              "\n",
              "[30103 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSavMqbOq-Aa",
        "outputId": "cb56c543-6383-4af1-f9ee-015d3e441432"
      },
      "source": [
        "pip install Sastrawi"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAb0VFKgrcOQ",
        "outputId": "78cbc181-4035-48c3-ef46-c7a13eb2fd98"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQtdu8WIrKKL",
        "outputId": "7adccc15-5971-438b-b124-fcae5bbef270"
      },
      "source": [
        "# Loading Stopwords: Ada beberapa cara\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "factory = StopWordRemoverFactory()\n",
        "\n",
        "NLTK_StopWords = stopwords.words('english')\n",
        "Sastrawi_StopWords_id = factory.get_stop_words()\n",
        "\n",
        "df=open('/content/kapsel/stopword_en/stopword_en.txt',\"r\",encoding=\"utf-8\", errors='replace')\n",
        "en_stop = df.readlines()\n",
        "df.close()\n",
        "en_stop = [t.strip().lower() for t in en_stop]\n",
        "\n",
        "df=open('/content/kapsel/stopword/stopword.txt',\"r\",encoding=\"utf-8\", errors='replace')\n",
        "id_stop = df.readlines()\n",
        "df.close()\n",
        "id_stop = [t.strip().lower() for t in id_stop]\n",
        "\n",
        "N = 10\n",
        "print(NLTK_StopWords[:N])\n",
        "print(Sastrawi_StopWords_id[:N])\n",
        "print(en_stop[:N])\n",
        "print(id_stop[:N])\n",
        "print(len(Sastrawi_StopWords_id), len(id_stop), len(NLTK_StopWords), len(en_stop))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
            "['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua']\n",
            "['&gt', '&lt', '&nbsp', 'a', 'able', 'about', 'above', 'abst', 'accordance', 'according']\n",
            "['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir']\n",
            "126 758 179 2659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpIQVGAOz60h"
      },
      "source": [
        "datafinal=data[['full_text']]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YeAcannh0H54",
        "outputId": "55187b0e-5824-43d8-8b50-39c48327e025"
      },
      "source": [
        "datafinal"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @perupadata: Resmi: harga tes RT-PCR turun....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @detikfinance: #mostpop Mantan Sekretaris M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@mindweul Biar bersatu dgn pcr gepengmu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @ManassaDaeng: Pemerimtah sudah menurunkan ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@2pec__ agr pcr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30098</th>\n",
              "      <td>Antisipasi Gelombang III Covid-19, BNN Prov Su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30099</th>\n",
              "      <td>@Hilmi28 dan saya ngalamin ðŸ˜‘\\nswab antigen 170...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30100</th>\n",
              "      <td>mana tadi idung aing di rojok dalem pisan, ya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30101</th>\n",
              "      <td>ples td di sekolah tbtb swab dadakan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30102</th>\n",
              "      <td>KOMPAK, TIGA PILAR BERSAMA PUSKESMAS JETIS TUR...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30103 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               full_text\n",
              "0      RT @perupadata: Resmi: harga tes RT-PCR turun....\n",
              "1      RT @detikfinance: #mostpop Mantan Sekretaris M...\n",
              "2                @mindweul Biar bersatu dgn pcr gepengmu\n",
              "3      RT @ManassaDaeng: Pemerimtah sudah menurunkan ...\n",
              "4                                        @2pec__ agr pcr\n",
              "...                                                  ...\n",
              "30098  Antisipasi Gelombang III Covid-19, BNN Prov Su...\n",
              "30099  @Hilmi28 dan saya ngalamin ðŸ˜‘\\nswab antigen 170...\n",
              "30100  mana tadi idung aing di rojok dalem pisan, ya ...\n",
              "30101               ples td di sekolah tbtb swab dadakan\n",
              "30102  KOMPAK, TIGA PILAR BERSAMA PUSKESMAS JETIS TUR...\n",
              "\n",
              "[30103 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzNFh1XT36bn",
        "outputId": "7dac24f5-4346-448e-ee4a-c9cfd15516cc"
      },
      "source": [
        "pip install docx2txt"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.7/dist-packages (0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuO2s2gT4E5v",
        "outputId": "bc55b003-aaec-415b-cd12-d4712f790c08"
      },
      "source": [
        "pip install unidecode"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3lzkpMctFcg"
      },
      "source": [
        "import re, os, itertools, docx2txt\n",
        "from tqdm import tqdm\n",
        "#from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from spacy.lang.id import Indonesian\n",
        "from html import unescape\n",
        "from unidecode import unidecode\n",
        "import pandas as pd\n",
        "#from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "#from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from nltk.tokenize import TweetTokenizer; Tokenizer = TweetTokenizer(reduce_len=True)\n",
        "#from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import PorterStemmer;ps = PorterStemmer()\n",
        "from string import punctuation\n",
        "#from pattern.web import PDF\n",
        "from bz2 import BZ2File as bz2\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from textblob import TextBlob \n",
        "#from NLP_Models import openewfile as of"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-K5_jcq35Ay"
      },
      "source": [
        "def crawlFiles(dPath, types = None):\n",
        "    #dPath = 'C:/Temp', types ='pdf'\n",
        "    if types:\n",
        "        return [dPath+'/'+f for f in os.listdir(dPath) if f.endswith('.'+types)]\n",
        "    else:\n",
        "        return [dPath+'/'+f for f in os.listdir(dPath)]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZsV95kM4jXj"
      },
      "source": [
        "def readBz2(file):\n",
        "    with bz2(file, \"r\") as bzData:\n",
        "        txt = []\n",
        "        for line in bzData:\n",
        "            try:\n",
        "                txt.append(line.strip().decode('utf-8','replace'))\n",
        "            except:\n",
        "                pass\n",
        "    return ' '.join(txt)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iV8dxwP4nk0"
      },
      "source": [
        "def LoadDocuments(dPath=None,types=None, file = None): # types = ['pdf','doc','docx','txt','bz2']\n",
        "    Files, Docs = [], []\n",
        "    if types:\n",
        "        for tipe in types:\n",
        "            Files += crawlFiles(dPath,tipe)\n",
        "    if file:\n",
        "        Files = [file]\n",
        "    if not types and not file: # get all files regardless of their extensions\n",
        "        Files += crawlFiles(dPath)\n",
        "    for f in Files:\n",
        "#        if f[-3:].lower()=='pdf':\n",
        "#            try:\n",
        "#                Docs.append(PDF(f).string)\n",
        "#            except:\n",
        "#                print('error reading{0}'.format(f))\n",
        "        if f[-3:].lower()=='txt':\n",
        "            try:\n",
        "                df=open(f,\"r\",encoding=\"utf-8\", errors='replace')\n",
        "                Docs.append(df.readlines());df.close()\n",
        "            except:\n",
        "                print('error reading{0}'.format(f))\n",
        "        elif f[-3:].lower()=='bz2':\n",
        "            try:\n",
        "                Docs.append(readBz2(f))\n",
        "            except:\n",
        "                print('error reading{0}'.format(f))\n",
        "        elif f[-4:].lower()=='docx':\n",
        "            try:\n",
        "                Docs.append(docx2txt.process(f))\n",
        "            except:\n",
        "                print('error reading{0}'.format(f))\n",
        "        elif f[-3:].lower()=='csv':\n",
        "            Docs.append(pd.read_csv(f))\n",
        "        else:\n",
        "            print('Unsupported format {0}'.format(f))\n",
        "    if file:\n",
        "        Docs = Docs\n",
        "    return Docs, Files"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg5K-MEa4rg7"
      },
      "source": [
        "def LoadStopWords(lang, sentiment = True):\n",
        "    L = lang.lower().strip()\n",
        "    if sentiment:\n",
        "        if L == 'en' or L == 'english' or L == 'inggris':\n",
        "            lemmatizer = WordNetLemmatizer()\n",
        "            stops = set([t.strip() for t in LoadDocuments(file = '/content/kapsel/stopword')[0]])\n",
        "        elif L == 'id' or L == 'indonesia' or L == 'indonesian':\n",
        "            lemmatizer = Indonesian()\n",
        "            stops = set([t.strip() for t in LoadDocuments(file ='/content/kapsel/stopword_noise')[0]])\n",
        "        else:\n",
        "            print('Warning! Languange not recognized. Empty stopword given')\n",
        "            stops = set(); lemmatizer = None\n",
        "    else:\n",
        "        if L == 'en' or L == 'english' or L == 'inggris':\n",
        "            lemmatizer = WordNetLemmatizer()\n",
        "            stops = set([t.strip() for t in LoadDocuments(file = '/content/kapsel/stopword_en')[0]])\n",
        "        elif L == 'id' or L == 'indonesia' or L == 'indonesian':\n",
        "            lemmatizer = Indonesian()\n",
        "            stops = set([t.strip() for t in LoadDocuments(file = '/content/kapsel/stopword')[0]])\n",
        "        else:\n",
        "            print('Warning! Languange not recognized. Empty stopword given')\n",
        "            stops = set(); lemmatizer = None\n",
        "    return stops, lemmatizer"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxsnIQsf4uQx"
      },
      "source": [
        "def fixTags(T):\n",
        "    getHashtags = re.compile(r\"#(\\w+)\")\n",
        "    pisahtags = re.compile(r'[A-Z][^A-Z]*')\n",
        "    t = T\n",
        "    tagS = re.findall(getHashtags, T)\n",
        "    for tag in tagS:\n",
        "        proper_words = ' '.join(re.findall(pisahtags, tagS[0]))\n",
        "        t = t.replace('#'+tag, proper_words)\n",
        "    return t"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmYZJQWe4xWE"
      },
      "source": [
        "def getTags(T):\n",
        "    getHashtags = re.compile(r\"#(\\w+)\")\n",
        "    tagS = re.findall(getHashtags, T)\n",
        "    isitag = []\n",
        "    for tag in tagS:       \n",
        "        tag = '#'+tag\n",
        "        isitag.append(tag)\n",
        "    \n",
        "    return ', '.join(isitag)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHrZ6OpJ41x8"
      },
      "source": [
        "def cleanText(T, fix={}, pattern2 = False, lang = 'id', lemma=None, stops = set(), symbols_remove = False, numbers_remove = False, hashtag_remove = False, min_charLen = 0):\n",
        "    # lang & stopS only 2 options : 'en' atau 'id'\n",
        "    # symbols ASCII atau alnum\n",
        "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    pattern1 = re.compile(r'pic.twitter.com/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    if pattern2:\n",
        "        pattern2 = re.compile(r'@(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+') #remove@\n",
        "        t = re.sub(pattern2, ' ',T)\n",
        "    else:\n",
        "        t = T\n",
        "    t = re.sub(pattern,' ',t) #remove urls if any\n",
        "    t = re.sub(pattern1,' ',t)\n",
        "    t = unescape(t) # html entities fix\n",
        "    if hashtag_remove:\n",
        "        t = fixTags(t) # fix abcDef\n",
        "    else:\n",
        "        t = t\n",
        "    t = t.lower().strip() # lowercase\n",
        "    t = unidecode(t)\n",
        "    t = ''.join(''.join(s)[:2] for _, s in itertools.groupby(t)) # remove repetition\n",
        "    t = sent_tokenize(t) # sentence segmentation. String to list\n",
        "    for i, K in enumerate(t):\n",
        "        if symbols_remove:\n",
        "            K = re.sub(r'[^.,a-zA-Z0-9 \\n\\.]',' ',K)\n",
        "            K = K.replace(',',' ').replace('.',' ')\n",
        "            K = ''.join(c for c in K if c not in punctuation)\n",
        "            K = re.sub('\\s+',' ',K).strip()\n",
        "        \n",
        "        if numbers_remove:\n",
        "            K = re.sub(r'[0-9]',' ',K)\n",
        "            K = re.sub('\\s+',' ',K)\n",
        "            \n",
        "        cleanList = []\n",
        "        if lang =='en':\n",
        "            listKata = word_tokenize(K) # word tokenize\n",
        "            for token in listKata:\n",
        "                if token in fix.keys():\n",
        "                    token = fix[token]\n",
        "                if lemma:\n",
        "                    token = lemma.lemmatize(token)\n",
        "                if stops:\n",
        "                    if len(token)>=min_charLen and token not in stops:\n",
        "                        cleanList.append(token)\n",
        "                else:\n",
        "                    if len(token)>=min_charLen:\n",
        "                        cleanList.append(token)\n",
        "            t[i] = ' '.join(cleanList)\n",
        "        else:\n",
        "            if lemma:\n",
        "                K = lemma(K)\n",
        "                listKata = [token.text for token in K]\n",
        "            else:\n",
        "                listKata = TextBlob(K).words\n",
        "                \n",
        "            for token in listKata:\n",
        "                if token in fix.keys():\n",
        "                    token = fix[token]\n",
        "                \n",
        "                if lemma:\n",
        "                    token = lemma(token)[0].lemma_\n",
        "                    #token = stemmer.stem(token)\n",
        "                if stops:    \n",
        "                    if len(token)>=min_charLen and token not in stops:\n",
        "                        cleanList.append(token)\n",
        "                else:\n",
        "                    if len(token)>=min_charLen:\n",
        "                        cleanList.append(token)\n",
        "            t[i] = ' '.join(cleanList).lstrip()\n",
        "    return ' '.join(t) # Return kalimat lagi\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BeJ4kQf45zN"
      },
      "source": [
        "def cleanText_(T, fix={}, min_charLen = 0):\n",
        "    t = T\n",
        "    t = t.lower().strip() # lowercase\n",
        "    t = unidecode(t)\n",
        "    t = ''.join(''.join(s)[:2] for _, s in itertools.groupby(t)) # remove repetition\n",
        "    t = sent_tokenize(t) # sentence segmentation. String to list\n",
        "    for i, K in enumerate(t):\n",
        "        cleanList = []\n",
        "        listKata = TextBlob(K).words\n",
        "        for token in listKata:\n",
        "            if token in fix.keys():\n",
        "                token = fix[token]\n",
        "                cleanList.append(token)\n",
        "            else:\n",
        "                if len(token)>=min_charLen:\n",
        "                    cleanList.append(token)\n",
        "        t[i] = ' '.join(cleanList).lstrip()\n",
        "    return ' '.join(t) # Return kalimat lagi\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q8G6k6T48jS"
      },
      "source": [
        "def handlingnegation (full_text):\n",
        "    match = re.compile(r'(tidak|kurang|bukan|jangan|tapi|tetapi) (\\w+)').findall(full_text)\n",
        "    match = list(set(match))\n",
        "    for i,word in enumerate(match): \n",
        "        if ' '.join(match[i]) in full_text:\n",
        "            kata = full_text.replace(' '.join(match[i]), str(match[i][0])+' '+'negx'+str(match[i][1]))\n",
        "            full_text = kata\n",
        "    return full_text"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKZeng_X4_Mx"
      },
      "source": [
        "def handlingporn (full_text):\n",
        "    match = re.compile(r'(video|foto|photo) (\\w+)').findall(full_text)\n",
        "    match = list(set(match))\n",
        "    for i,word in enumerate(match): \n",
        "        if ' '.join(match[i]) in full_text:\n",
        "            kata = full_text.replace(' '.join(match[i]), str(match[i][0])+' '+'pornx'+str(match[i][1]))\n",
        "            full_text = kata\n",
        "    return full_text"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCBFwNqE5C0j"
      },
      "source": [
        "def print_Topics(model, feature_names, Top_Topics, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_[:Top_Topics]):\n",
        "        print(\"Topic #%d:\" %(topic_idx+1))\n",
        "        print(\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfQuwF0B5HVA"
      },
      "source": [
        "def getTopics(Txt,n_topics=5, Top_Words=7):\n",
        "    #Txt = [t['nlp'] for t in Tweets] # cleaned: stopwords, stemming\n",
        "    tf_vectorizer = CountVectorizer(strip_accents = 'unicode', token_pattern = r'\\b[a-zA-Z]{3,}\\b', max_df = 0.95, min_df = 2)\n",
        "    dtm_tf = tf_vectorizer.fit_transform(Txt)\n",
        "    tf_terms = tf_vectorizer.get_feature_names()\n",
        "    lda_tf = LDA(n_components=n_topics, learning_method='online', random_state=0).fit(dtm_tf)   \n",
        "    vsm_topics = lda_tf.transform(dtm_tf); doc_topic =  [a.argmax()+1 for a in tqdm(vsm_topics)] # topic of docs\n",
        "    print('In total there are {0} major topics, distributed as follows'.format(len(set(doc_topic))))\n",
        "    fig4 = plt.figure(); fig4.add_subplot(111)\n",
        "    plt.hist(np.array(doc_topic), alpha=0.5); plt.show()\n",
        "    print('Printing top {0} Topics, with top {1} Words:'.format(n_topics, Top_Words))\n",
        "    print_Topics(lda_tf, tf_terms, n_topics, Top_Words)\n",
        "    return lda_tf, dtm_tf, tf_vectorizer"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M97EUpo8ip_"
      },
      "source": [
        "#from NLP_Models import TextMining as tm\n",
        "import time\n",
        "#from NLP_Models import openewfile as of\n",
        "from tqdm import tqdm\n",
        "#import swifter"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFSO5X_08m56"
      },
      "source": [
        "def cleanningtext(data, both = True, onlyclean = False, sentiment = False):\n",
        "    print('Cleaning Text')\n",
        "    fSlang = '/content/kapsel/slangword/slang.txt'\n",
        "    bahasa = 'id'\n",
        "    stops, lemmatizer = LoadStopWords(bahasa, sentiment = sentiment)\n",
        "    sw=open(fSlang,encoding='utf-8', errors ='ignore', mode='r');SlangS=sw.readlines();sw.close()\n",
        "    SlangS = {slang.strip().split(':')[0]:slang.strip().split(':')[1] for slang in SlangS}\n",
        "  \n",
        "    start_time = time.time()\n",
        "    tqdm.pandas()\n",
        "    \n",
        "    if both:\n",
        "        data['full_text'] = data['full_text'].astype('str')\n",
        "        data['full_text'] = data['full_text'].str.lower()\n",
        "        data = data[~data.full_text.str.contains('unavailable')]\n",
        "        data['cleaned_text'] = data['full_text'].progress_apply(lambda x : cleanText(x,fix=SlangS, pattern2 = True, lang = bahasa, lemma=lemmatizer, stops = stops, symbols_remove = True, numbers_remove = True, hashtag_remove=False, min_charLen = 2))\n",
        "        data['cleaned_text'] = data['cleaned_text'].progress_apply(lambda x : handlingnegation(x))\n",
        "        #data['cleaned_text'] = data['cleaned_text'].progress_apply(lambda x : handlingporn(x))\n",
        "    elif onlyclean: \n",
        "        data['cleaned_text'] = data['full_text'].progress_apply(lambda x : cleanText(x, fix=SlangS, pattern2 = True, lang = bahasa, lemma=lemmatizer, stops = stops, symbols_remove = True, numbers_remove = True, hashtag_remove=False, min_charLen = 3))\n",
        "    else:\n",
        "        data['cleaned_text'] = data['full_text'].progress_apply(lambda x : handlingnegation(x))\n",
        "    \n",
        "    data = data[data['cleaned_text'].notna()]\n",
        "    print(\"%s seconds\" %(time.time()-start_time))\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "_nfKJS295SHo",
        "outputId": "b4b88b71-2846-453f-ebc0-611a3a69a7ad"
      },
      "source": [
        "data"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>id_str</th>\n",
              "      <th>full_text</th>\n",
              "      <th>truncated</th>\n",
              "      <th>display_text_range</th>\n",
              "      <th>entities</th>\n",
              "      <th>metadata</th>\n",
              "      <th>source</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_status_id_str</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>in_reply_to_user_id_str</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>user</th>\n",
              "      <th>geo</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>place</th>\n",
              "      <th>contributors</th>\n",
              "      <th>retweeted_status</th>\n",
              "      <th>is_quote_status</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>favorited</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>lang</th>\n",
              "      <th>quoted_status_id</th>\n",
              "      <th>quoted_status_id_str</th>\n",
              "      <th>quoted_status</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>extended_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-10-30 14:04:48+00:00</td>\n",
              "      <td>1454449208606429184</td>\n",
              "      <td>1454449208606429184</td>\n",
              "      <td>RT @perupadata: Resmi: harga tes RT-PCR turun....</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 139]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 105504840, 'id_str': '105504840', 'name...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Wed Oct 27 10:28:23 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-10-30 14:04:27+00:00</td>\n",
              "      <td>1454449121989824519</td>\n",
              "      <td>1454449121989824512</td>\n",
              "      <td>RT @detikfinance: #mostpop Mantan Sekretaris M...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 139]</td>\n",
              "      <td>{'hashtags': [{'text': 'mostpop', 'indices': [...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1019403817295605760, 'id_str': '1019403...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Sat Oct 30 13:48:14 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-10-30 14:04:26+00:00</td>\n",
              "      <td>1454449116356907016</td>\n",
              "      <td>1454449116356907008</td>\n",
              "      <td>@mindweul Biar bersatu dgn pcr gepengmu</td>\n",
              "      <td>False</td>\n",
              "      <td>[10, 39]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>1.454449e+18</td>\n",
              "      <td>1.454449e+18</td>\n",
              "      <td>1.451753e+18</td>\n",
              "      <td>1.451753e+18</td>\n",
              "      <td>mindweul</td>\n",
              "      <td>{'id': 1160690231865008128, 'id_str': '1160690...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-10-30 14:04:25+00:00</td>\n",
              "      <td>1454449111919325189</td>\n",
              "      <td>1454449111919325184</td>\n",
              "      <td>RT @ManassaDaeng: Pemerimtah sudah menurunkan ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 140]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1192569236494749696, 'id_str': '1192569...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'created_at': 'Sat Oct 30 01:33:28 +0000 2021...</td>\n",
              "      <td>False</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-10-30 14:04:12+00:00</td>\n",
              "      <td>1454449059004092417</td>\n",
              "      <td>1454449059004092416</td>\n",
              "      <td>@2pec__ agr pcr</td>\n",
              "      <td>False</td>\n",
              "      <td>[8, 15]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>1.454449e+18</td>\n",
              "      <td>1.454449e+18</td>\n",
              "      <td>7.982780e+17</td>\n",
              "      <td>7.982780e+17</td>\n",
              "      <td>2pec__</td>\n",
              "      <td>{'id': 1107842529590951936, 'id_str': '1107842...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30098</th>\n",
              "      <td>2021-10-27 03:38:19+00:00</td>\n",
              "      <td>1453204387006857223</td>\n",
              "      <td>1453204387006857216</td>\n",
              "      <td>Antisipasi Gelombang III Covid-19, BNN Prov Su...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 273]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 2923492080, 'id_str': '2923492080', 'na...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'media': [{'id': 1453203835674005507, 'id_str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30099</th>\n",
              "      <td>2021-10-27 03:38:18+00:00</td>\n",
              "      <td>1453204381885554691</td>\n",
              "      <td>1453204381885554688</td>\n",
              "      <td>@Hilmi28 dan saya ngalamin ðŸ˜‘\\nswab antigen 170...</td>\n",
              "      <td>False</td>\n",
              "      <td>[9, 151]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>1.452798e+18</td>\n",
              "      <td>1.452798e+18</td>\n",
              "      <td>6.506718e+07</td>\n",
              "      <td>6.506718e+07</td>\n",
              "      <td>Hilmi28</td>\n",
              "      <td>{'id': 1120730554645630976, 'id_str': '1120730...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30100</th>\n",
              "      <td>2021-10-27 03:36:42+00:00</td>\n",
              "      <td>1453203977349177348</td>\n",
              "      <td>1453203977349177344</td>\n",
              "      <td>mana tadi idung aing di rojok dalem pisan, ya ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 62]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1417918233349292032, 'id_str': '1417918...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30101</th>\n",
              "      <td>2021-10-27 03:36:31+00:00</td>\n",
              "      <td>1453203931870347264</td>\n",
              "      <td>1453203931870347264</td>\n",
              "      <td>ples td di sekolah tbtb swab dadakan</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 36]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1376937657939333126, 'id_str': '1376937...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30102</th>\n",
              "      <td>2021-10-27 03:34:31+00:00</td>\n",
              "      <td>1453203430420271106</td>\n",
              "      <td>1453203430420271104</td>\n",
              "      <td>KOMPAK, TIGA PILAR BERSAMA PUSKESMAS JETIS TUR...</td>\n",
              "      <td>False</td>\n",
              "      <td>[0, 255]</td>\n",
              "      <td>{'hashtags': [{'text': 'OpsYustisi', 'indices'...</td>\n",
              "      <td>{'iso_language_code': 'in', 'result_type': 're...</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>{'id': 1323130916206645248, 'id_str': '1323130...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>in</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'media': [{'id': 1453203020896878603, 'id_str...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30103 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     created_at  ...                                  extended_entities\n",
              "0     2021-10-30 14:04:48+00:00  ...                                                NaN\n",
              "1     2021-10-30 14:04:27+00:00  ...                                                NaN\n",
              "2     2021-10-30 14:04:26+00:00  ...                                                NaN\n",
              "3     2021-10-30 14:04:25+00:00  ...                                                NaN\n",
              "4     2021-10-30 14:04:12+00:00  ...                                                NaN\n",
              "...                         ...  ...                                                ...\n",
              "30098 2021-10-27 03:38:19+00:00  ...  {'media': [{'id': 1453203835674005507, 'id_str...\n",
              "30099 2021-10-27 03:38:18+00:00  ...                                                NaN\n",
              "30100 2021-10-27 03:36:42+00:00  ...                                                NaN\n",
              "30101 2021-10-27 03:36:31+00:00  ...                                                NaN\n",
              "30102 2021-10-27 03:34:31+00:00  ...  {'media': [{'id': 1453203020896878603, 'id_str...\n",
              "\n",
              "[30103 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8IkOM5X95Qc",
        "outputId": "3ee48143-1229-4465-9544-ec7637902f10"
      },
      "source": [
        "dataakhir = cleanningtext(data=data, both=True, onlyclean=False, sentiment=False)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning Text\n",
            "Unsupported format /content/kapsel/stopword\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30103/30103 [01:15<00:00, 398.93it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30103/30103 [00:00<00:00, 195612.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75.82113647460938 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3p7931khRl7",
        "outputId": "2995a356-a226-4473-c9d6-2d5717f15e62"
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['created_at', 'id', 'id_str', 'full_text', 'truncated',\n",
              "       'display_text_range', 'entities', 'metadata', 'source',\n",
              "       'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
              "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
              "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
              "       'contributors', 'retweeted_status', 'is_quote_status', 'retweet_count',\n",
              "       'favorite_count', 'favorited', 'retweeted', 'lang', 'quoted_status_id',\n",
              "       'quoted_status_id_str', 'quoted_status', 'possibly_sensitive',\n",
              "       'extended_entities'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcyvvLiAhS1m",
        "outputId": "80046fb1-2a11-4408-e835-ef1cfe8cc31a"
      },
      "source": [
        "dataakhir.keys()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['created_at', 'id', 'id_str', 'full_text', 'truncated',\n",
              "       'display_text_range', 'entities', 'metadata', 'source',\n",
              "       'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
              "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
              "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
              "       'contributors', 'retweeted_status', 'is_quote_status', 'retweet_count',\n",
              "       'favorite_count', 'favorited', 'retweeted', 'lang', 'quoted_status_id',\n",
              "       'quoted_status_id_str', 'quoted_status', 'possibly_sensitive',\n",
              "       'extended_entities', 'cleaned_text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATAZr1CDhVtP"
      },
      "source": [
        "voyant = dataakhir[['cleaned_text']]"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Y9sfzHpmhfQd",
        "outputId": "e7e80c7b-7e52-4ad9-9736-a5538c305130"
      },
      "source": [
        "voyant"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt resmi harga tes rt pcr turun pemerintah men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rt mostpop mantan sekretaris menteri bumn muha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>biar bersatu dengan pcr gepengmu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rt pemerimtah sudah menurunkan tes pcr menjadi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>agr pcr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30098</th>\n",
              "      <td>antisipasi gelombang ii covid bnn prov sumbar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30099</th>\n",
              "      <td>dan saya ngalamin swab antigen rb positif kela...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30100</th>\n",
              "      <td>mana tadi idung aing di rojok dalem pisan ya k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30101</th>\n",
              "      <td>ples td di sekolah tbtb swab dadakan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30102</th>\n",
              "      <td>kompak tiga pilar bersama puskesmas jetis turu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30103 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            cleaned_text\n",
              "0      rt resmi harga tes rt pcr turun pemerintah men...\n",
              "1      rt mostpop mantan sekretaris menteri bumn muha...\n",
              "2                       biar bersatu dengan pcr gepengmu\n",
              "3      rt pemerimtah sudah menurunkan tes pcr menjadi...\n",
              "4                                                agr pcr\n",
              "...                                                  ...\n",
              "30098  antisipasi gelombang ii covid bnn prov sumbar ...\n",
              "30099  dan saya ngalamin swab antigen rb positif kela...\n",
              "30100  mana tadi idung aing di rojok dalem pisan ya k...\n",
              "30101               ples td di sekolah tbtb swab dadakan\n",
              "30102  kompak tiga pilar bersama puskesmas jetis turu...\n",
              "\n",
              "[30103 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OVkd23bhgiY"
      },
      "source": [
        "voyant.to_csv('/content/kapsel/data/voyant.txt', index=False)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZjyntxlh0ew"
      },
      "source": [
        "dataoke = dataakhir[['full_text', 'cleaned_text']]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "S8XwoFwJif7B",
        "outputId": "3a630b72-113c-43ca-82f9-f95a0d05007d"
      },
      "source": [
        "dataoke.full_text[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'rt @perupadata: resmi: harga tes rt-pcr turun. pemerintah mengumumkan sore ini.\\n\\ndi jawa-bali, harga tes pcr maksimal rp275.000, sementaraâ€¦'"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DSpFziA-ihDk",
        "outputId": "aa2237c0-31d9-4e92-974d-18822e7f04a5"
      },
      "source": [
        "dataoke.cleaned_text[0]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'rt resmi harga tes rt pcr turun pemerintah mengumumkan sore ini di jawa bali harga tes pcr maksimal rp sementara'"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjIwJtPNi9t2"
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}